{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Install,Setting up selenium**","metadata":{}},{"cell_type":"code","source":"# install google chrome\n!wget https://dl.google.com/linux/linux_signing_key.pub\n!sudo apt-key add linux_signing_key.pub\n!echo 'deb [arch=amd64] http://dl.google.com/linux/chrome/deb/ stable main' >> /etc/apt/sources.list.d/google-chrome.list\n!sudo apt-get -y update\n!sudo apt-get install -y google-chrome-stable","metadata":{"execution":{"iopub.status.busy":"2023-05-07T17:27:48.562563Z","iopub.execute_input":"2023-05-07T17:27:48.563112Z","iopub.status.idle":"2023-05-07T17:28:22.570190Z","shell.execute_reply.started":"2023-05-07T17:27:48.563080Z","shell.execute_reply":"2023-05-07T17:28:22.568768Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"--2023-05-07 17:27:49--  https://dl.google.com/linux/linux_signing_key.pub\nResolving dl.google.com (dl.google.com)... 108.177.111.91, 108.177.111.190, 108.177.111.136, ...\nConnecting to dl.google.com (dl.google.com)|108.177.111.91|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 14605 (14K) [application/octet-stream]\nSaving to: ‘linux_signing_key.pub’\n\nlinux_signing_key.p 100%[===================>]  14.26K  --.-KB/s    in 0s      \n\n2023-05-07 17:27:49 (51.5 MB/s) - ‘linux_signing_key.pub’ saved [14605/14605]\n\nOK\nGet:1 http://packages.cloud.google.com/apt gcsfuse-focal InRelease [5002 B]\nGet:2 https://packages.cloud.google.com/apt cloud-sdk InRelease [6361 B]       \nGet:3 https://packages.cloud.google.com/apt google-fast-socket InRelease [5015 B]\nGet:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease [1581 B]\nGet:5 http://packages.cloud.google.com/apt gcsfuse-focal/main amd64 Packages [2217 B]\nGet:6 http://dl.google.com/linux/chrome/deb stable InRelease [1825 B]          \nHit:7 http://archive.ubuntu.com/ubuntu focal InRelease                         \nGet:8 http://security.ubuntu.com/ubuntu focal-security InRelease [114 kB]\nGet:9 https://packages.cloud.google.com/apt cloud-sdk/main amd64 Packages [434 kB]\nGet:10 http://archive.ubuntu.com/ubuntu focal-updates InRelease [114 kB]       \nGet:11 https://packages.cloud.google.com/apt google-fast-socket/main amd64 Packages [447 B]\nGet:12 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  Packages [1009 kB]\nGet:13 http://dl.google.com/linux/chrome/deb stable/main amd64 Packages [1077 B]\nGet:14 http://archive.ubuntu.com/ubuntu focal-backports InRelease [108 kB]     \nGet:15 http://security.ubuntu.com/ubuntu focal-security/universe amd64 Packages [1039 kB]\nGet:16 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 Packages [1334 kB]\nGet:17 http://security.ubuntu.com/ubuntu focal-security/multiverse amd64 Packages [28.5 kB]\nGet:18 http://security.ubuntu.com/ubuntu focal-security/main amd64 Packages [2669 kB]\nGet:19 http://archive.ubuntu.com/ubuntu focal-updates/multiverse amd64 Packages [31.2 kB]\nGet:20 http://archive.ubuntu.com/ubuntu focal-updates/restricted amd64 Packages [2341 kB]\nGet:21 http://security.ubuntu.com/ubuntu focal-security/restricted amd64 Packages [2203 kB]\nGet:22 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 Packages [3150 kB]\nFetched 14.6 MB in 2s (5857 kB/s)                                              \nReading package lists... Done\nReading package lists... Done\nBuilding dependency tree       \nReading state information... Done\nThe following additional packages will be installed:\n  fonts-liberation libgbm1 libu2f-udev libudev1 libwayland-server0 udev\nThe following NEW packages will be installed:\n  fonts-liberation google-chrome-stable libgbm1 libu2f-udev libwayland-server0\n  udev\nThe following packages will be upgraded:\n  libudev1\n1 upgraded, 6 newly installed, 0 to remove and 79 not upgraded.\nNeed to get 97.3 MB of archives.\nAfter this operation, 326 MB of additional disk space will be used.\nGet:1 http://archive.ubuntu.com/ubuntu focal/main amd64 fonts-liberation all 1:1.07.4-11 [822 kB]\nGet:2 http://dl.google.com/linux/chrome/deb stable/main amd64 google-chrome-stable amd64 113.0.5672.63-1 [95.0 MB]\nGet:3 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libwayland-server0 amd64 1.18.0-1ubuntu0.1 [31.3 kB]\nGet:4 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libgbm1 amd64 21.2.6-0ubuntu0.1~20.04.2 [29.2 kB]\nGet:5 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libudev1 amd64 245.4-4ubuntu3.21 [75.9 kB]\nGet:6 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 udev amd64 245.4-4ubuntu3.21 [1366 kB]\nGet:7 http://archive.ubuntu.com/ubuntu focal/main amd64 libu2f-udev all 1.1.10-1 [6108 B]\nFetched 97.3 MB in 1s (82.8 MB/s)                                             \nSelecting previously unselected package fonts-liberation.\n(Reading database ... 111522 files and directories currently installed.)\nPreparing to unpack .../fonts-liberation_1%3a1.07.4-11_all.deb ...\nUnpacking fonts-liberation (1:1.07.4-11) ...\nSelecting previously unselected package libwayland-server0:amd64.\nPreparing to unpack .../libwayland-server0_1.18.0-1ubuntu0.1_amd64.deb ...\nUnpacking libwayland-server0:amd64 (1.18.0-1ubuntu0.1) ...\nSelecting previously unselected package libgbm1:amd64.\nPreparing to unpack .../libgbm1_21.2.6-0ubuntu0.1~20.04.2_amd64.deb ...\nUnpacking libgbm1:amd64 (21.2.6-0ubuntu0.1~20.04.2) ...\nPreparing to unpack .../libudev1_245.4-4ubuntu3.21_amd64.deb ...\nUnpacking libudev1:amd64 (245.4-4ubuntu3.21) over (245.4-4ubuntu3.19) ...\nSetting up libudev1:amd64 (245.4-4ubuntu3.21) ...\nSelecting previously unselected package udev.\n(Reading database ... 111559 files and directories currently installed.)\nPreparing to unpack .../udev_245.4-4ubuntu3.21_amd64.deb ...\nUnpacking udev (245.4-4ubuntu3.21) ...\nSelecting previously unselected package libu2f-udev.\nPreparing to unpack .../libu2f-udev_1.1.10-1_all.deb ...\nUnpacking libu2f-udev (1.1.10-1) ...\nSelecting previously unselected package google-chrome-stable.\nPreparing to unpack .../google-chrome-stable_113.0.5672.63-1_amd64.deb ...\nUnpacking google-chrome-stable (113.0.5672.63-1) ...\nSetting up libwayland-server0:amd64 (1.18.0-1ubuntu0.1) ...\nSetting up libgbm1:amd64 (21.2.6-0ubuntu0.1~20.04.2) ...\nSetting up udev (245.4-4ubuntu3.21) ...\ninvoke-rc.d: could not determine current runlevel\ninvoke-rc.d: policy-rc.d denied execution of start.\nSetting up fonts-liberation (1:1.07.4-11) ...\nSetting up libu2f-udev (1.1.10-1) ...\nFailed to send reload request: No such file or directory\nSetting up google-chrome-stable (113.0.5672.63-1) ...\nupdate-alternatives: using /usr/bin/google-chrome-stable to provide /usr/bin/x-www-browser (x-www-browser) in auto mode\nupdate-alternatives: using /usr/bin/google-chrome-stable to provide /usr/bin/gnome-www-browser (gnome-www-browser) in auto mode\nupdate-alternatives: using /usr/bin/google-chrome-stable to provide /usr/bin/google-chrome (google-chrome) in auto mode\nProcessing triggers for libc-bin (2.31-0ubuntu9.9) ...\nProcessing triggers for systemd (245.4-4ubuntu3.19) ...\nProcessing triggers for man-db (2.9.1-1) ...\nProcessing triggers for fontconfig (2.13.1-2ubuntu3) ...\nProcessing triggers for mime-support (3.64ubuntu1) ...\n","output_type":"stream"}]},{"cell_type":"code","source":"# install chromedriver\n# !apt-get install -y qq unzip\n!wget -O /tmp/chromedriver.zip http://chromedriver.storage.googleapis.com/`curl -sS chromedriver.storage.googleapis.com/LATEST_RELEASE`/chromedriver_linux64.zip\n!unzip /tmp/chromedriver.zip chromedriver -d /usr/local/bin/","metadata":{"execution":{"iopub.status.busy":"2023-05-07T17:28:22.572807Z","iopub.execute_input":"2023-05-07T17:28:22.573334Z","iopub.status.idle":"2023-05-07T17:28:24.827178Z","shell.execute_reply.started":"2023-05-07T17:28:22.573169Z","shell.execute_reply":"2023-05-07T17:28:24.826006Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"--2023-05-07 17:28:23--  http://chromedriver.storage.googleapis.com/113.0.5672.63/chromedriver_linux64.zip\nResolving chromedriver.storage.googleapis.com (chromedriver.storage.googleapis.com)... 173.194.192.128, 2607:f8b0:4001:c0e::80\nConnecting to chromedriver.storage.googleapis.com (chromedriver.storage.googleapis.com)|173.194.192.128|:80... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 7315061 (7.0M) [application/zip]\nSaving to: ‘/tmp/chromedriver.zip’\n\n/tmp/chromedriver.z 100%[===================>]   6.98M  --.-KB/s    in 0.02s   \n\n2023-05-07 17:28:23 (290 MB/s) - ‘/tmp/chromedriver.zip’ saved [7315061/7315061]\n\nArchive:  /tmp/chromedriver.zip\n  inflating: /usr/local/bin/chromedriver  \n","output_type":"stream"}]},{"cell_type":"code","source":"# install selenium\n!sudo apt install -y python3-selenium\n!pip install selenium==3.141.0 > /dev/null","metadata":{"execution":{"iopub.status.busy":"2023-05-07T17:28:24.828863Z","iopub.execute_input":"2023-05-07T17:28:24.829193Z","iopub.status.idle":"2023-05-07T17:28:57.013436Z","shell.execute_reply.started":"2023-05-07T17:28:24.829162Z","shell.execute_reply":"2023-05-07T17:28:57.011413Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Reading package lists... Done\nBuilding dependency tree       \nReading state information... Done\nThe following additional packages will be installed:\n  apparmor chromium-browser chromium-chromedriver liblzo2-2 snapd\n  squashfs-tools\nSuggested packages:\n  apparmor-profiles-extra apparmor-utils zenity | kdialog\nThe following NEW packages will be installed:\n  apparmor chromium-browser chromium-chromedriver liblzo2-2 python3-selenium\n  snapd squashfs-tools\n0 upgraded, 7 newly installed, 0 to remove and 79 not upgraded.\nNeed to get 38.7 MB of archives.\nAfter this operation, 174 MB of additional disk space will be used.\nGet:1 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 apparmor amd64 2.13.3-7ubuntu5.2 [502 kB]\nGet:2 http://archive.ubuntu.com/ubuntu focal/main amd64 liblzo2-2 amd64 2.10-2 [50.8 kB]\nGet:3 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 squashfs-tools amd64 1:4.4-1ubuntu0.3 [117 kB]\nGet:4 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 snapd amd64 2.58+20.04 [37.9 MB]\nGet:5 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 chromium-browser amd64 1:85.0.4183.83-0ubuntu0.20.04.3 [48.5 kB]\nGet:6 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 chromium-chromedriver amd64 1:85.0.4183.83-0ubuntu0.20.04.3 [2496 B]\nGet:7 http://archive.ubuntu.com/ubuntu focal/universe amd64 python3-selenium all 4.0.0~a1+dfsg1-1.1 [86.2 kB]\nFetched 38.7 MB in 3s (13.8 MB/s)           \u001b[0m\u001b[33m\nPreconfiguring packages ...\n\n\u001b7\u001b[0;23r\u001b8\u001b[1ASelecting previously unselected package apparmor.\n(Reading database ... 111793 files and directories currently installed.)\nPreparing to unpack .../apparmor_2.13.3-7ubuntu5.2_amd64.deb ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  0%]\u001b[49m\u001b[39m [..........................................................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  3%]\u001b[49m\u001b[39m [##........................................................] \u001b8Unpacking apparmor (2.13.3-7ubuntu5.2) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  7%]\u001b[49m\u001b[39m [####......................................................] \u001b8Selecting previously unselected package liblzo2-2:amd64.\nPreparing to unpack .../liblzo2-2_2.10-2_amd64.deb ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 10%]\u001b[49m\u001b[39m [######....................................................] \u001b8Unpacking liblzo2-2:amd64 (2.10-2) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 14%]\u001b[49m\u001b[39m [########..................................................] \u001b8Selecting previously unselected package squashfs-tools.\nPreparing to unpack .../squashfs-tools_1%3a4.4-1ubuntu0.3_amd64.deb ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 17%]\u001b[49m\u001b[39m [#########.................................................] \u001b8Unpacking squashfs-tools (1:4.4-1ubuntu0.3) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 21%]\u001b[49m\u001b[39m [############..............................................] \u001b8Selecting previously unselected package snapd.\nPreparing to unpack .../snapd_2.58+20.04_amd64.deb ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 24%]\u001b[49m\u001b[39m [##############............................................] \u001b8Unpacking snapd (2.58+20.04) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 28%]\u001b[49m\u001b[39m [################..........................................] \u001b8Setting up apparmor (2.13.3-7ubuntu5.2) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 31%]\u001b[49m\u001b[39m [##################........................................] \u001b8Created symlink /etc/systemd/system/sysinit.target.wants/apparmor.service → /lib/systemd/system/apparmor.service.\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 34%]\u001b[49m\u001b[39m [###################.......................................] \u001b8Setting up liblzo2-2:amd64 (2.10-2) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 38%]\u001b[49m\u001b[39m [######################....................................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 41%]\u001b[49m\u001b[39m [########################..................................] \u001b8Setting up squashfs-tools (1:4.4-1ubuntu0.3) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 45%]\u001b[49m\u001b[39m [##########################................................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 48%]\u001b[49m\u001b[39m [############################..............................] \u001b8Setting up snapd (2.58+20.04) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 52%]\u001b[49m\u001b[39m [#############################.............................] \u001b8Created symlink /etc/systemd/system/multi-user.target.wants/snapd.aa-prompt-listener.service → /lib/systemd/system/snapd.aa-prompt-listener.service.\nCreated symlink /etc/systemd/system/multi-user.target.wants/snapd.apparmor.service → /lib/systemd/system/snapd.apparmor.service.\nCreated symlink /etc/systemd/system/multi-user.target.wants/snapd.autoimport.service → /lib/systemd/system/snapd.autoimport.service.\nCreated symlink /etc/systemd/system/multi-user.target.wants/snapd.core-fixup.service → /lib/systemd/system/snapd.core-fixup.service.\nCreated symlink /etc/systemd/system/multi-user.target.wants/snapd.recovery-chooser-trigger.service → /lib/systemd/system/snapd.recovery-chooser-trigger.service.\nCreated symlink /etc/systemd/system/multi-user.target.wants/snapd.seeded.service → /lib/systemd/system/snapd.seeded.service.\nCreated symlink /etc/systemd/system/cloud-final.service.wants/snapd.seeded.service → /lib/systemd/system/snapd.seeded.service.\nCreated symlink /etc/systemd/system/multi-user.target.wants/snapd.service → /lib/systemd/system/snapd.service.\nCreated symlink /etc/systemd/system/timers.target.wants/snapd.snap-repair.timer → /lib/systemd/system/snapd.snap-repair.timer.\nCreated symlink /etc/systemd/system/sockets.target.wants/snapd.socket → /lib/systemd/system/snapd.socket.\nCreated symlink /etc/systemd/system/final.target.wants/snapd.system-shutdown.service → /lib/systemd/system/snapd.system-shutdown.service.\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 55%]\u001b[49m\u001b[39m [################################..........................] \u001b8Selecting previously unselected package chromium-browser.\n(Reading database ... 112089 files and directories currently installed.)\nPreparing to unpack .../chromium-browser_1%3a85.0.4183.83-0ubuntu0.20.04.3_amd64.deb ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 59%]\u001b[49m\u001b[39m [##################################........................] \u001b8=> Installing the chromium snap\n==> Checking connectivity with the snap store\n===> System doesn't have a working snapd, skipping\nUnpacking chromium-browser (1:85.0.4183.83-0ubuntu0.20.04.3) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 62%]\u001b[49m\u001b[39m [####################################......................] \u001b8Selecting previously unselected package chromium-chromedriver.\nPreparing to unpack .../chromium-chromedriver_1%3a85.0.4183.83-0ubuntu0.20.04.3_amd64.deb ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 66%]\u001b[49m\u001b[39m [######################################....................] \u001b8Unpacking chromium-chromedriver (1:85.0.4183.83-0ubuntu0.20.04.3) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 69%]\u001b[49m\u001b[39m [#######################################...................] \u001b8Selecting previously unselected package python3-selenium.\nPreparing to unpack .../python3-selenium_4.0.0~a1+dfsg1-1.1_all.deb ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 72%]\u001b[49m\u001b[39m [##########################################................] \u001b8Unpacking python3-selenium (4.0.0~a1+dfsg1-1.1) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 76%]\u001b[49m\u001b[39m [############################################..............] \u001b8Setting up python3-selenium (4.0.0~a1+dfsg1-1.1) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 79%]\u001b[49m\u001b[39m [##############################################............] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 83%]\u001b[49m\u001b[39m [################################################..........] \u001b8Setting up chromium-browser (1:85.0.4183.83-0ubuntu0.20.04.3) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 86%]\u001b[49m\u001b[39m [##################################################........] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 90%]\u001b[49m\u001b[39m [####################################################......] \u001b8Setting up chromium-chromedriver (1:85.0.4183.83-0ubuntu0.20.04.3) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 93%]\u001b[49m\u001b[39m [#####################################################.....] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 97%]\u001b[49m\u001b[39m [########################################################..] \u001b8Processing triggers for mime-support (3.64ubuntu1) ...\nProcessing triggers for hicolor-icon-theme (0.17-2) ...\nProcessing triggers for libc-bin (2.31-0ubuntu9.9) ...\nProcessing triggers for systemd (245.4-4ubuntu3.19) ...\nProcessing triggers for man-db (2.9.1-1) ...\nProcessing triggers for dbus (1.12.16-2ubuntu2.3) ...\n\n\u001b7\u001b[0;24r\u001b8\u001b[1A\u001b[J\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"# To check Google Chrome's version\n!google-chrome --version","metadata":{"execution":{"iopub.status.busy":"2023-05-07T17:28:57.017349Z","iopub.execute_input":"2023-05-07T17:28:57.017812Z","iopub.status.idle":"2023-05-07T17:28:58.187351Z","shell.execute_reply.started":"2023-05-07T17:28:57.017769Z","shell.execute_reply":"2023-05-07T17:28:58.186187Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Google Chrome 113.0.5672.63 \n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install -U sentence-transformers \n!pip install tqdm","metadata":{"execution":{"iopub.status.busy":"2023-05-07T17:28:58.189647Z","iopub.execute_input":"2023-05-07T17:28:58.189992Z","iopub.status.idle":"2023-05-07T17:29:21.347831Z","shell.execute_reply.started":"2023-05-07T17:28:58.189960Z","shell.execute_reply":"2023-05-07T17:29:21.346462Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Collecting sentence-transformers\n  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=4.6.0 in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (4.27.4)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (4.64.1)\nRequirement already satisfied: torch>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (1.13.0)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (0.14.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (1.21.6)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (1.0.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (1.7.3)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (3.2.4)\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (0.1.97)\nRequirement already satisfied: huggingface-hub>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (0.13.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.9.0)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (23.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.28.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.4.0)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.11.4)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.13.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2021.11.10)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from nltk->sentence-transformers) (1.16.0)\nRequirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->sentence-transformers) (1.2.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->sentence-transformers) (3.1.0)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.7/site-packages (from torchvision->sentence-transformers) (9.4.0)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->huggingface-hub>=0.4.0->sentence-transformers) (3.11.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.1.1)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (1.26.14)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2022.12.7)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.4)\nBuilding wheels for collected packages: sentence-transformers\n  Building wheel for sentence-transformers (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125938 sha256=320a4d3d7384cd951736fa8045f2c1a1d8d5bb2511bc2e120b382e5181a2af81\n  Stored in directory: /root/.cache/pip/wheels/83/71/2b/40d17d21937fed496fb99145227eca8f20b4891240ff60c86f\nSuccessfully built sentence-transformers\nInstalling collected packages: sentence-transformers\nSuccessfully installed sentence-transformers-2.2.2\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (4.64.1)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"markdown","source":"# Let's get started!","metadata":{}},{"cell_type":"markdown","source":"## **Import packages**\n","metadata":{}},{"cell_type":"code","source":"import torch\nfrom sentence_transformers import SentenceTransformer\n\nif torch.cuda.is_available():\n    device = torch.device('cuda')\nelse:\n    device = torch.device('cpu')\n\nmodel_path = \"../input/sbert-models/paraphrase-multilingual-mpnet-base-v2\"\n\nmodel = SentenceTransformer(model_path, device=device)\n# embedding = model.encode(text, device=device)","metadata":{"execution":{"iopub.status.busy":"2023-05-07T18:14:51.817142Z","iopub.execute_input":"2023-05-07T18:14:51.818217Z","iopub.status.idle":"2023-05-07T18:14:56.618661Z","shell.execute_reply.started":"2023-05-07T18:14:51.818175Z","shell.execute_reply":"2023-05-07T18:14:56.617534Z"},"trusted":true},"execution_count":135,"outputs":[]},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport re\nimport string\nimport nltk\nimport gensim\nfrom gensim.models import Word2Vec\n# from nltk.corpus import stopwords\n# from nltk.tokenize import word_tokenize\nimport sentence_transformers\nfrom scipy import spatial\nfrom tqdm.notebook import tqdm\ntqdm.pandas()\n# \n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n\n\nimport requests\nfrom bs4 import BeautifulSoup\nimport csv\nimport pandas as pd\nimport re\nfrom selenium import webdriver\nfrom selenium.webdriver.common.by import By\nfrom selenium.webdriver.common.keys import Keys\nfrom selenium.webdriver.support.ui import WebDriverWait\nfrom selenium.webdriver.support import expected_conditions as EC\nimport time\n\noptions = webdriver.ChromeOptions()\noptions.add_argument('--headless')\noptions.add_argument(\"--no-sandbox\")\noptions.add_argument(\"--headless\")\noptions.add_argument(\"--disable-gpu\")\n# Set up the Selenium driver\ndriver = webdriver.Chrome(options=options)\n# driver = webdriver.Chrome(PATH)","metadata":{"execution":{"iopub.status.busy":"2023-05-07T18:18:09.348079Z","iopub.execute_input":"2023-05-07T18:18:09.349133Z","iopub.status.idle":"2023-05-07T18:18:11.021836Z","shell.execute_reply.started":"2023-05-07T18:18:09.349091Z","shell.execute_reply":"2023-05-07T18:18:11.020337Z"},"trusted":true},"execution_count":157,"outputs":[{"name":"stdout","text":"/kaggle/input/descriptionembeddings/D-embeddings.npy\n/kaggle/input/sbert-models/paraphrase-multilingual-mpnet-base-v2/config.json\n/kaggle/input/sbert-models/paraphrase-multilingual-mpnet-base-v2/README.md\n/kaggle/input/sbert-models/paraphrase-multilingual-mpnet-base-v2/tokenizer.json\n/kaggle/input/sbert-models/paraphrase-multilingual-mpnet-base-v2/tokenizer_config.json\n/kaggle/input/sbert-models/paraphrase-multilingual-mpnet-base-v2/sentence_bert_config.json\n/kaggle/input/sbert-models/paraphrase-multilingual-mpnet-base-v2/pytorch_model.bin\n/kaggle/input/sbert-models/paraphrase-multilingual-mpnet-base-v2/config_sentence_transformers.json\n/kaggle/input/sbert-models/paraphrase-multilingual-mpnet-base-v2/modules.json\n/kaggle/input/sbert-models/paraphrase-multilingual-mpnet-base-v2/special_tokens_map.json\n/kaggle/input/sbert-models/paraphrase-multilingual-mpnet-base-v2/sentencepiece.bpe.model\n/kaggle/input/sbert-models/paraphrase-multilingual-mpnet-base-v2/1_Pooling/config.json\n/kaggle/input/sbert-models/paraphrase-xlm-r-multilingual-v1/config.json\n/kaggle/input/sbert-models/paraphrase-xlm-r-multilingual-v1/README.md\n/kaggle/input/sbert-models/paraphrase-xlm-r-multilingual-v1/tokenizer.json\n/kaggle/input/sbert-models/paraphrase-xlm-r-multilingual-v1/tokenizer_config.json\n/kaggle/input/sbert-models/paraphrase-xlm-r-multilingual-v1/sentence_bert_config.json\n/kaggle/input/sbert-models/paraphrase-xlm-r-multilingual-v1/pytorch_model.bin\n/kaggle/input/sbert-models/paraphrase-xlm-r-multilingual-v1/config_sentence_transformers.json\n/kaggle/input/sbert-models/paraphrase-xlm-r-multilingual-v1/modules.json\n/kaggle/input/sbert-models/paraphrase-xlm-r-multilingual-v1/special_tokens_map.json\n/kaggle/input/sbert-models/paraphrase-xlm-r-multilingual-v1/sentencepiece.bpe.model\n/kaggle/input/sbert-models/paraphrase-xlm-r-multilingual-v1/1_Pooling/config.json\n/kaggle/input/sbert-models/paraphrase-multilingual-MiniLM-L12-v2/config.json\n/kaggle/input/sbert-models/paraphrase-multilingual-MiniLM-L12-v2/README.md\n/kaggle/input/sbert-models/paraphrase-multilingual-MiniLM-L12-v2/tokenizer.json\n/kaggle/input/sbert-models/paraphrase-multilingual-MiniLM-L12-v2/unigram.json\n/kaggle/input/sbert-models/paraphrase-multilingual-MiniLM-L12-v2/tokenizer_config.json\n/kaggle/input/sbert-models/paraphrase-multilingual-MiniLM-L12-v2/sentence_bert_config.json\n/kaggle/input/sbert-models/paraphrase-multilingual-MiniLM-L12-v2/pytorch_model.bin\n/kaggle/input/sbert-models/paraphrase-multilingual-MiniLM-L12-v2/config_sentence_transformers.json\n/kaggle/input/sbert-models/paraphrase-multilingual-MiniLM-L12-v2/modules.json\n/kaggle/input/sbert-models/paraphrase-multilingual-MiniLM-L12-v2/special_tokens_map.json\n/kaggle/input/sbert-models/paraphrase-multilingual-MiniLM-L12-v2/1_Pooling/config.json\n/kaggle/input/sbert-models/xlm-roberta-base/config.json\n/kaggle/input/sbert-models/xlm-roberta-base/README.md\n/kaggle/input/sbert-models/xlm-roberta-base/tokenizer.json\n/kaggle/input/sbert-models/xlm-roberta-base/tokenizer_config.json\n/kaggle/input/sbert-models/xlm-roberta-base/sentence_bert_config.json\n/kaggle/input/sbert-models/xlm-roberta-base/pytorch_model.bin\n/kaggle/input/sbert-models/xlm-roberta-base/config_sentence_transformers.json\n/kaggle/input/sbert-models/xlm-roberta-base/modules.json\n/kaggle/input/sbert-models/xlm-roberta-base/special_tokens_map.json\n/kaggle/input/sbert-models/xlm-roberta-base/sentencepiece.bpe.model\n/kaggle/input/sbert-models/xlm-roberta-base/1_Pooling/config.json\n/kaggle/input/bert-embedding1/embeddings.npy\n/kaggle/input/comprehensive-literary-greats-dataset/books_1.Best_Books_Ever.csv\n/kaggle/input/bert-embedding2/embeddings (1).npy\n/kaggle/input/bert-embedding3/embeddings1.npy\n/kaggle/input/fulltext/D-embeddings (1).npy\n/kaggle/input/bert-embedding4/embeddings2 (1).npy\n/kaggle/input/bert-embeddings/embeddings2.npy\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"}]},{"cell_type":"code","source":"input_dataframe = pd.read_csv(\"/kaggle/input/comprehensive-literary-greats-dataset/books_1.Best_Books_Ever.csv\")\nembedding1 = np.load('/kaggle/input/bert-embedding1/embeddings.npy', allow_pickle = True)\nembedding2 = np.load('/kaggle/input/bert-embedding2/embeddings (1).npy', allow_pickle = True)\nembedding4 = np.load('/kaggle/input/bert-embedding4/embeddings2 (1).npy', allow_pickle = True)\nembedding5 = np.load('/kaggle/input/bert-embeddings/embeddings2.npy', allow_pickle = True)\n\nembedding_Description = np.load('/kaggle/input/descriptionembeddings/D-embeddings.npy', allow_pickle=True)\nembedding_beautified = np.load('/kaggle/input/fulltext/D-embeddings (1).npy', allow_pickle=True)\n\npd1 = pd.DataFrame(embedding1)\npd2 = pd.DataFrame(embedding2)\npd4 = pd.DataFrame(embedding4)\npd5 = pd.DataFrame(embedding5)\n\nfinal = pd.concat([pd1, pd2,pd4, pd5])\nfinal.rename(columns={0:\"embeddings\"}, inplace= True)\n# input_dataframe.head()\nfinal.index = pd.RangeIndex(start=0, stop = 0+len(final), step = 1)\nfinal = final.reset_index()\nfinalAllDescriptionEmbeddings = final\n\nfin_emb = []\nfor i in range(len(embedding_Description)):\n    fin_emb.append(embedding_Description[i].tolist())\nfin_emb\n\nfin_emb1 = []\nfor i in range(len(embedding_Description)):\n    fin_emb1.append(embedding_Description[i].tolist())\nfin_emb1\n\nfinalDescriptionEmbeddings = pd.DataFrame({'embeddings':fin_emb})\nfinalBeautifiedEmbeddings = pd.DataFrame({'embeddings':fin_emb1})\nfinalBeautifiedEmbeddings = finalBeautifiedEmbeddings.reset_index()\nfinalDescriptionEmbeddings = finalDescriptionEmbeddings.reset_index()\n# finalDescriptionEmbeddings","metadata":{"execution":{"iopub.status.busy":"2023-05-07T18:14:58.203585Z","iopub.execute_input":"2023-05-07T18:14:58.204063Z","iopub.status.idle":"2023-05-07T18:15:08.684182Z","shell.execute_reply.started":"2023-05-07T18:14:58.204007Z","shell.execute_reply":"2023-05-07T18:15:08.683114Z"},"trusted":true},"execution_count":137,"outputs":[]},{"cell_type":"markdown","source":"# **RECOMMENDATION MODELS**","metadata":{}},{"cell_type":"markdown","source":"# **PREPROCESS DATA FOR RECOMMENDATION**","metadata":{}},{"cell_type":"code","source":"input_dataframe.head()","metadata":{"execution":{"iopub.status.busy":"2023-05-07T18:15:08.687218Z","iopub.execute_input":"2023-05-07T18:15:08.687656Z","iopub.status.idle":"2023-05-07T18:15:08.725026Z","shell.execute_reply.started":"2023-05-07T18:15:08.687617Z","shell.execute_reply":"2023-05-07T18:15:08.723535Z"},"trusted":true},"execution_count":138,"outputs":[{"execution_count":138,"output_type":"execute_result","data":{"text/plain":"                                        bookId  \\\n0                     2767052-the-hunger-games   \n1  2.Harry_Potter_and_the_Order_of_the_Phoenix   \n2                   2657.To_Kill_a_Mockingbird   \n3                     1885.Pride_and_Prejudice   \n4                               41865.Twilight   \n\n                                       title                 series  \\\n0                           The Hunger Games    The Hunger Games #1   \n1  Harry Potter and the Order of the Phoenix        Harry Potter #5   \n2                      To Kill a Mockingbird  To Kill a Mockingbird   \n3                        Pride and Prejudice                    NaN   \n4                                   Twilight   The Twilight Saga #1   \n\n                                      author  rating  \\\n0                            Suzanne Collins    4.33   \n1  J.K. Rowling, Mary GrandPré (Illustrator)    4.50   \n2                                 Harper Lee    4.28   \n3  Jane Austen, Anna Quindlen (Introduction)    4.26   \n4                            Stephenie Meyer    3.60   \n\n                                         description language           isbn  \\\n0  WINNING MEANS FAME AND FORTUNE.LOSING MEANS CE...  English  9780439023481   \n1  There is a door at the end of a silent corrido...  English  9780439358071   \n2  The unforgettable novel of a childhood in a sl...  English  9999999999999   \n3  Alternate cover edition of ISBN 9780679783268S...  English  9999999999999   \n4  About three things I was absolutely positive.\\...  English  9780316015844   \n\n                                              genres  \\\n0  ['Young Adult', 'Fiction', 'Dystopia', 'Fantas...   \n1  ['Fantasy', 'Young Adult', 'Fiction', 'Magic',...   \n2  ['Classics', 'Fiction', 'Historical Fiction', ...   \n3  ['Classics', 'Fiction', 'Romance', 'Historical...   \n4  ['Young Adult', 'Fantasy', 'Romance', 'Vampire...   \n\n                                          characters  ... firstPublishDate  \\\n0  ['Katniss Everdeen', 'Peeta Mellark', 'Cato (H...  ...              NaN   \n1  ['Sirius Black', 'Draco Malfoy', 'Ron Weasley'...  ...         06/21/03   \n2  ['Scout Finch', 'Atticus Finch', 'Jem Finch', ...  ...         07/11/60   \n3  ['Mr. Bennet', 'Mrs. Bennet', 'Jane Bennet', '...  ...         01/28/13   \n4  ['Edward Cullen', 'Jacob Black', 'Laurent', 'R...  ...         10/05/05   \n\n                                              awards numRatings  \\\n0  ['Locus Award Nominee for Best Young Adult Boo...    6376780   \n1  ['Bram Stoker Award for Works for Young Reader...    2507623   \n2  ['Pulitzer Prize for Fiction (1961)', 'Audie A...    4501075   \n3                                                 []    2998241   \n4  ['Georgia Peach Book Award (2007)', 'Buxtehude...    4964519   \n\n                                      ratingsByStars likedPercent  \\\n0  ['3444695', '1921313', '745221', '171994', '93...         96.0   \n1  ['1593642', '637516', '222366', '39573', '14526']         98.0   \n2  ['2363896', '1333153', '573280', '149952', '80...         95.0   \n3  ['1617567', '816659', '373311', '113934', '767...         94.0   \n4  ['1751460', '1113682', '1008686', '542017', '5...         78.0   \n\n                                             setting  \\\n0  ['District 12, Panem', 'Capitol, Panem', 'Pane...   \n1  ['Hogwarts School of Witchcraft and Wizardry (...   \n2               ['Maycomb, Alabama (United States)']   \n3  ['United Kingdom', 'Derbyshire, England (Unite...   \n4  ['Forks, Washington (United States)', 'Phoenix...   \n\n                                            coverImg  bbeScore bbeVotes  price  \n0  https://i.gr-assets.com/images/S/compressed.ph...   2993816    30516   5.09  \n1  https://i.gr-assets.com/images/S/compressed.ph...   2632233    26923   7.38  \n2  https://i.gr-assets.com/images/S/compressed.ph...   2269402    23328    NaN  \n3  https://i.gr-assets.com/images/S/compressed.ph...   1983116    20452    NaN  \n4  https://i.gr-assets.com/images/S/compressed.ph...   1459448    14874    2.1  \n\n[5 rows x 25 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>bookId</th>\n      <th>title</th>\n      <th>series</th>\n      <th>author</th>\n      <th>rating</th>\n      <th>description</th>\n      <th>language</th>\n      <th>isbn</th>\n      <th>genres</th>\n      <th>characters</th>\n      <th>...</th>\n      <th>firstPublishDate</th>\n      <th>awards</th>\n      <th>numRatings</th>\n      <th>ratingsByStars</th>\n      <th>likedPercent</th>\n      <th>setting</th>\n      <th>coverImg</th>\n      <th>bbeScore</th>\n      <th>bbeVotes</th>\n      <th>price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2767052-the-hunger-games</td>\n      <td>The Hunger Games</td>\n      <td>The Hunger Games #1</td>\n      <td>Suzanne Collins</td>\n      <td>4.33</td>\n      <td>WINNING MEANS FAME AND FORTUNE.LOSING MEANS CE...</td>\n      <td>English</td>\n      <td>9780439023481</td>\n      <td>['Young Adult', 'Fiction', 'Dystopia', 'Fantas...</td>\n      <td>['Katniss Everdeen', 'Peeta Mellark', 'Cato (H...</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>['Locus Award Nominee for Best Young Adult Boo...</td>\n      <td>6376780</td>\n      <td>['3444695', '1921313', '745221', '171994', '93...</td>\n      <td>96.0</td>\n      <td>['District 12, Panem', 'Capitol, Panem', 'Pane...</td>\n      <td>https://i.gr-assets.com/images/S/compressed.ph...</td>\n      <td>2993816</td>\n      <td>30516</td>\n      <td>5.09</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2.Harry_Potter_and_the_Order_of_the_Phoenix</td>\n      <td>Harry Potter and the Order of the Phoenix</td>\n      <td>Harry Potter #5</td>\n      <td>J.K. Rowling, Mary GrandPré (Illustrator)</td>\n      <td>4.50</td>\n      <td>There is a door at the end of a silent corrido...</td>\n      <td>English</td>\n      <td>9780439358071</td>\n      <td>['Fantasy', 'Young Adult', 'Fiction', 'Magic',...</td>\n      <td>['Sirius Black', 'Draco Malfoy', 'Ron Weasley'...</td>\n      <td>...</td>\n      <td>06/21/03</td>\n      <td>['Bram Stoker Award for Works for Young Reader...</td>\n      <td>2507623</td>\n      <td>['1593642', '637516', '222366', '39573', '14526']</td>\n      <td>98.0</td>\n      <td>['Hogwarts School of Witchcraft and Wizardry (...</td>\n      <td>https://i.gr-assets.com/images/S/compressed.ph...</td>\n      <td>2632233</td>\n      <td>26923</td>\n      <td>7.38</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2657.To_Kill_a_Mockingbird</td>\n      <td>To Kill a Mockingbird</td>\n      <td>To Kill a Mockingbird</td>\n      <td>Harper Lee</td>\n      <td>4.28</td>\n      <td>The unforgettable novel of a childhood in a sl...</td>\n      <td>English</td>\n      <td>9999999999999</td>\n      <td>['Classics', 'Fiction', 'Historical Fiction', ...</td>\n      <td>['Scout Finch', 'Atticus Finch', 'Jem Finch', ...</td>\n      <td>...</td>\n      <td>07/11/60</td>\n      <td>['Pulitzer Prize for Fiction (1961)', 'Audie A...</td>\n      <td>4501075</td>\n      <td>['2363896', '1333153', '573280', '149952', '80...</td>\n      <td>95.0</td>\n      <td>['Maycomb, Alabama (United States)']</td>\n      <td>https://i.gr-assets.com/images/S/compressed.ph...</td>\n      <td>2269402</td>\n      <td>23328</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1885.Pride_and_Prejudice</td>\n      <td>Pride and Prejudice</td>\n      <td>NaN</td>\n      <td>Jane Austen, Anna Quindlen (Introduction)</td>\n      <td>4.26</td>\n      <td>Alternate cover edition of ISBN 9780679783268S...</td>\n      <td>English</td>\n      <td>9999999999999</td>\n      <td>['Classics', 'Fiction', 'Romance', 'Historical...</td>\n      <td>['Mr. Bennet', 'Mrs. Bennet', 'Jane Bennet', '...</td>\n      <td>...</td>\n      <td>01/28/13</td>\n      <td>[]</td>\n      <td>2998241</td>\n      <td>['1617567', '816659', '373311', '113934', '767...</td>\n      <td>94.0</td>\n      <td>['United Kingdom', 'Derbyshire, England (Unite...</td>\n      <td>https://i.gr-assets.com/images/S/compressed.ph...</td>\n      <td>1983116</td>\n      <td>20452</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>41865.Twilight</td>\n      <td>Twilight</td>\n      <td>The Twilight Saga #1</td>\n      <td>Stephenie Meyer</td>\n      <td>3.60</td>\n      <td>About three things I was absolutely positive.\\...</td>\n      <td>English</td>\n      <td>9780316015844</td>\n      <td>['Young Adult', 'Fantasy', 'Romance', 'Vampire...</td>\n      <td>['Edward Cullen', 'Jacob Black', 'Laurent', 'R...</td>\n      <td>...</td>\n      <td>10/05/05</td>\n      <td>['Georgia Peach Book Award (2007)', 'Buxtehude...</td>\n      <td>4964519</td>\n      <td>['1751460', '1113682', '1008686', '542017', '5...</td>\n      <td>78.0</td>\n      <td>['Forks, Washington (United States)', 'Phoenix...</td>\n      <td>https://i.gr-assets.com/images/S/compressed.ph...</td>\n      <td>1459448</td>\n      <td>14874</td>\n      <td>2.1</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 25 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"input_dataframe.dropna(subset=[\"description\"], inplace=True)\n\nurl_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\ndef remove_url(text):   \n    return re.sub(url_pattern, r'', text)\n\nhtml_pattern = re.compile('<[^>]*>')\ndef clean_html_tags(text):\n    return re.sub(html_pattern, r'', text)\n\npunctuations = string.punctuation\ndef remove_punctuations(text):\n    return text.translate(str.maketrans('', '', punctuations))\n\ndef text_lowercase(text):\n    return text.lower()\n\ndef preprocess(input_dataframe):\n    input_dataframe.description = input_dataframe.description.apply(remove_url)\n    input_dataframe.description = input_dataframe.description.apply(clean_html_tags)\n    input_dataframe.description = input_dataframe.description.apply(remove_punctuations)\n    input_dataframe.description = input_dataframe.description.apply(text_lowercase)\n    input_dataframe.dropna(subset=[\"description\"], inplace=True)\n#     input_dataframe.drop_duplicates()\n    return input_dataframe\n\n","metadata":{"execution":{"iopub.status.busy":"2023-05-07T18:15:08.727055Z","iopub.execute_input":"2023-05-07T18:15:08.727698Z","iopub.status.idle":"2023-05-07T18:15:08.767711Z","shell.execute_reply.started":"2023-05-07T18:15:08.727656Z","shell.execute_reply":"2023-05-07T18:15:08.766785Z"},"trusted":true},"execution_count":139,"outputs":[]},{"cell_type":"markdown","source":"# **FORMAT DATAFRAME FOR SPECIFIC RECOMMENDATION**","metadata":{}},{"cell_type":"code","source":"def getText(books_df):\n    liked_book_descriptionBeautified = []\n    for i in range(len(books_df)):\n        sentence = \" \"\n        sentence += \"Description of the book is - \" + str(books_df.iloc[i][\"description\"])\n        sentence += \". \"\n        sentence += \"The author of the book is - \" + books_df.iloc[i][\"author\"]\n        sentence += \". \"\n        sentence += \"The genres of the book are - \"\n        sentence +=  str(books_df.iloc[i][\"genres\"][1:-2])\n        sentence += \". \"\n        sentence += \"The rating of the book is - \" + str(books_df.iloc[i][\"ratings\"])\n        liked_book_descriptionBeautified.append(sentence)\n    liked_book_descriptionBeauty = pd.DataFrame()\n    liked_book_descriptionBeauty['description'] = liked_book_descriptionBeautified\n    liked_book_descriptionAll =books_df['description'] + books_df['author'] + str(books_df['genres']) \n    liked_book_description =books_df['description']\n    return liked_book_description","metadata":{"execution":{"iopub.status.busy":"2023-05-07T18:15:08.769407Z","iopub.execute_input":"2023-05-07T18:15:08.769826Z","iopub.status.idle":"2023-05-07T18:15:08.777897Z","shell.execute_reply.started":"2023-05-07T18:15:08.769773Z","shell.execute_reply":"2023-05-07T18:15:08.776331Z"},"trusted":true},"execution_count":140,"outputs":[]},{"cell_type":"code","source":"textAll = input_dataframe[['description', 'author', 'genres']].agg(' '.join, axis=1)\ndataAll = textAll\ntext = input_dataframe[\"description\"]\ndata = text\ndata.iloc[1]","metadata":{"execution":{"iopub.status.busy":"2023-05-07T18:15:08.779746Z","iopub.execute_input":"2023-05-07T18:15:08.780454Z","iopub.status.idle":"2023-05-07T18:15:12.062636Z","shell.execute_reply.started":"2023-05-07T18:15:08.780414Z","shell.execute_reply":"2023-05-07T18:15:12.061387Z"},"trusted":true},"execution_count":141,"outputs":[{"execution_count":141,"output_type":"execute_result","data":{"text/plain":"'There is a door at the end of a silent corridor. And it’s haunting Harry Pottter’s dreams. Why else would he be waking in the middle of the night, screaming in terror?Harry has a lot on his mind for this, his fifth year at Hogwarts: a Defense Against the Dark Arts teacher with a personality like poisoned honey; a big surprise on the Gryffindor Quidditch team; and the looming terror of the Ordinary Wizarding Level exams. But all these things pale next to the growing threat of He-Who-Must-Not-Be-Named - a threat that neither the magical government nor the authorities at Hogwarts can stop.As the grasp of darkness tightens, Harry must discover the true depth and strength of his friends, the importance of boundless loyalty, and the shocking price of unbearable sacrifice.His fate depends on them all.'"},"metadata":{}}]},{"cell_type":"markdown","source":"# **WORD2VEC Model for recommendation**","metadata":{}},{"cell_type":"code","source":"test = data\ntest_df = test.to_frame()\ntest_df.columns = ['concatenated']\nprint(test_df.columns)","metadata":{"execution":{"iopub.status.busy":"2023-04-27T08:34:21.710009Z","iopub.execute_input":"2023-04-27T08:34:21.710643Z","iopub.status.idle":"2023-04-27T08:34:21.719622Z","shell.execute_reply.started":"2023-04-27T08:34:21.710604Z","shell.execute_reply":"2023-04-27T08:34:21.718416Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"Index(['concatenated'], dtype='object')\n","output_type":"stream"}]},{"cell_type":"code","source":"def get_w2v(input):\n#     list_sentences = input.apply(lambda x: ' '.join(x.dropna().astype(str)), axis=1).tolist()\n    list_sentences = input['concatenated'].astype(str).tolist()\n    sentences = [sentence for text in list_sentences for sentence in nltk.sent_tokenize(text)]\n    stopwords = nltk.corpus.stopwords.words('english')\n    preprocessed_sentences = [[word.lower() for word in nltk.word_tokenize(sentence) if word.lower() not in stopwords] for sentence in sentences]\n    CBOW = gensim.models.Word2Vec(preprocessed_sentences, min_count = 1, vector_size = 100, window = 5, sg = 0)\n    SGRAM = gensim.models.Word2Vec(preprocessed_sentences, min_count = 1, vector_size = 100, window = 5, sg = 1)\n    return CBOW, SGRAM, preprocessed_sentences\n","metadata":{"execution":{"iopub.status.busy":"2023-04-27T08:34:21.927594Z","iopub.execute_input":"2023-04-27T08:34:21.928209Z","iopub.status.idle":"2023-04-27T08:34:21.936386Z","shell.execute_reply.started":"2023-04-27T08:34:21.928166Z","shell.execute_reply":"2023-04-27T08:34:21.935290Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"CBOW, SGRAM, preprocessed_sentences = get_w2v(test_df)","metadata":{"execution":{"iopub.status.busy":"2023-04-27T08:34:43.138879Z","iopub.execute_input":"2023-04-27T08:34:43.139977Z","iopub.status.idle":"2023-04-27T08:39:11.958368Z","shell.execute_reply.started":"2023-04-27T08:34:43.139921Z","shell.execute_reply":"2023-04-27T08:39:11.957172Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":" def getCBOWEmbeddingList(preprocessed_sentences):\n    w2v_embeddings = []\n    for i in range(len(preprocessed_sentences)):\n        for j in range(len(preprocessed_sentences[i])):\n            if j == 0:\n                test = np.zeros(100)\n                test += CBOW.wv[preprocessed_sentences[i][j]]\n            else:\n                test += CBOW.wv[preprocessed_sentences[i][j]]\n        test/=len(preprocessed_sentences[i])\n        w2v_embeddings.append(test)\n    return w2v_embeddings\nw2v_embeddings = getCBOWEmbeddingList(preprocessed_sentences)","metadata":{"execution":{"iopub.status.busy":"2023-04-27T08:40:02.584072Z","iopub.execute_input":"2023-04-27T08:40:02.585158Z","iopub.status.idle":"2023-04-27T08:40:17.254098Z","shell.execute_reply.started":"2023-04-27T08:40:02.585092Z","shell.execute_reply":"2023-04-27T08:40:17.252955Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"def findRecommendationW2V(w2v_embeddings):\n    test = w2v_embeddings[1]\n    test = np.asarray(test)\n    similarity = []\n    for i in w2v_embeddings:\n        i = np.asarray(i)\n        similarity.append(-1*(spatial.distance.cosine(i, test)-1))\n    sim = pd.DataFrame(similarity)\n    sim.columns = ['cosine_sim']\n    sim = sim.reset_index()\n    result = sim.sort_values(by=['cosine_sim'], ascending = False)\n    \n    recommend_books = []\n    print(result.iloc[2])\n    recommend_books.append(input_dataframe.iloc[int(result.iloc[1]['index'])])\n    recommend_books.append(input_dataframe.iloc[int(result.iloc[2]['index'])])\n    recommend_books.append(input_dataframe.iloc[int(result.iloc[3]['index'])])\n    recommend_books.append(input_dataframe.iloc[int(result.iloc[4]['index'])])\n    recommend_books.append(input_dataframe.iloc[int(result.iloc[5]['index'])])\n    recommend_books.append(input_dataframe.iloc[int(result.iloc[6]['index'])])\n    recommend_books.append(input_dataframe.iloc[int(result.iloc[7]['index'])])\n    recommend_books.append(input_dataframe.iloc[int(result.iloc[8]['index'])])\n    recommend_books.append(input_dataframe.iloc[int(result.iloc[9]['index'])])\n    recommend_books.append(input_dataframe.iloc[int(result.iloc[10]['index'])])\n    recommend_books = pd.DataFrame(recommend_books)\n    return recommend_books\n\nrecommended_books = findRecommendationW2V(w2v_embeddings)\nrecommended_books","metadata":{"execution":{"iopub.status.busy":"2023-04-27T08:49:30.650968Z","iopub.execute_input":"2023-04-27T08:49:30.652129Z","iopub.status.idle":"2023-04-27T08:49:32.259531Z","shell.execute_reply.started":"2023-04-27T08:49:30.652081Z","shell.execute_reply":"2023-04-27T08:49:32.257607Z"},"trusted":true},"execution_count":54,"outputs":[{"name":"stdout","text":"index         8352.000000\ncosine_sim       0.989316\nName: 8352, dtype: float64\n","output_type":"stream"},{"execution_count":54,"output_type":"execute_result","data":{"text/plain":"       index                                              title  \\\n18679  18679                   The Adventures of Jewel Cardwell   \n8403    8403                                       Thunderlight   \n26185  26185                     Everyday Food: Great Food Fast   \n20741  20741                                 The Immortal Lover   \n49741  49741                                        The Turning   \n14204  14204                                          RoseBlood   \n23920  23920                       The Curse of the Gloamglozer   \n20659  20659  Things Never To Call Your Wife: Porky, Meatloa...   \n51182  51182                             Emily Post's Etiquette   \n44637  44637                     The Liberation of Gabriel King   \n\n                                             description  \\\n18679  what would you do if you knew you’d inherited ...   \n8403   vibrant scale swathed wings… abilities that ca...   \n26185  no matter how busy you are at the end of the d...   \n20741  down through the ages of human history his nam...   \n49741  im no coward i want to make that perfectly cle...   \n14204  rune germaine moves to a boarding school outsi...   \n23920  fourteenyearold quint verginix is the only rem...   \n20659  this will probably be the most quirky fun and ...   \n51182  features twenty new chapters that cover such a...   \n44637  gabriel king was a born chicken hes afraid of ...   \n\n                                                  author  \\\n18679                    Fumi Hancock (Goodreads Author)   \n8403                   Adrienne Woods (Goodreads Author)   \n26185                                     Martha Stewart   \n20741                        A. White (Goodreads Author)   \n49741                                Jennifer Armintrout   \n14204                     A.G. Howard (Goodreads Author)   \n23920  Paul Stewart (Goodreads Author), Chris Riddell...   \n20659           Carhamel D. Chesecake (Goodreads Author)   \n51182                             Peggy Post, Emily Post   \n44637                      K.L. Going (Goodreads Author)   \n\n                                                  genres  likedPercent  \n18679                                    ['Young Adult']          92.0  \n8403   ['Dragons', 'Fantasy', 'Young Adult', 'Romance...          95.0  \n26185  ['Cookbooks', 'Cooking', 'Food', 'Nonfiction',...          90.0  \n20741                                                 []         100.0  \n49741  ['Vampires', 'Urban Fantasy', 'Paranormal', 'R...          84.0  \n14204  ['Fantasy', 'Young Adult', 'Retellings', 'Roma...          75.0  \n23920  ['Fantasy', 'Young Adult', 'Fiction', 'Adventu...          95.0  \n20659                                                 []         100.0  \n51182  ['Nonfiction', 'Reference', 'Self Help', 'Clas...          95.0  \n44637  ['Historical Fiction', 'Young Adult', 'Fiction...          94.0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>title</th>\n      <th>description</th>\n      <th>author</th>\n      <th>genres</th>\n      <th>likedPercent</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>18679</th>\n      <td>18679</td>\n      <td>The Adventures of Jewel Cardwell</td>\n      <td>what would you do if you knew you’d inherited ...</td>\n      <td>Fumi Hancock (Goodreads Author)</td>\n      <td>['Young Adult']</td>\n      <td>92.0</td>\n    </tr>\n    <tr>\n      <th>8403</th>\n      <td>8403</td>\n      <td>Thunderlight</td>\n      <td>vibrant scale swathed wings… abilities that ca...</td>\n      <td>Adrienne Woods (Goodreads Author)</td>\n      <td>['Dragons', 'Fantasy', 'Young Adult', 'Romance...</td>\n      <td>95.0</td>\n    </tr>\n    <tr>\n      <th>26185</th>\n      <td>26185</td>\n      <td>Everyday Food: Great Food Fast</td>\n      <td>no matter how busy you are at the end of the d...</td>\n      <td>Martha Stewart</td>\n      <td>['Cookbooks', 'Cooking', 'Food', 'Nonfiction',...</td>\n      <td>90.0</td>\n    </tr>\n    <tr>\n      <th>20741</th>\n      <td>20741</td>\n      <td>The Immortal Lover</td>\n      <td>down through the ages of human history his nam...</td>\n      <td>A. White (Goodreads Author)</td>\n      <td>[]</td>\n      <td>100.0</td>\n    </tr>\n    <tr>\n      <th>49741</th>\n      <td>49741</td>\n      <td>The Turning</td>\n      <td>im no coward i want to make that perfectly cle...</td>\n      <td>Jennifer Armintrout</td>\n      <td>['Vampires', 'Urban Fantasy', 'Paranormal', 'R...</td>\n      <td>84.0</td>\n    </tr>\n    <tr>\n      <th>14204</th>\n      <td>14204</td>\n      <td>RoseBlood</td>\n      <td>rune germaine moves to a boarding school outsi...</td>\n      <td>A.G. Howard (Goodreads Author)</td>\n      <td>['Fantasy', 'Young Adult', 'Retellings', 'Roma...</td>\n      <td>75.0</td>\n    </tr>\n    <tr>\n      <th>23920</th>\n      <td>23920</td>\n      <td>The Curse of the Gloamglozer</td>\n      <td>fourteenyearold quint verginix is the only rem...</td>\n      <td>Paul Stewart (Goodreads Author), Chris Riddell...</td>\n      <td>['Fantasy', 'Young Adult', 'Fiction', 'Adventu...</td>\n      <td>95.0</td>\n    </tr>\n    <tr>\n      <th>20659</th>\n      <td>20659</td>\n      <td>Things Never To Call Your Wife: Porky, Meatloa...</td>\n      <td>this will probably be the most quirky fun and ...</td>\n      <td>Carhamel D. Chesecake (Goodreads Author)</td>\n      <td>[]</td>\n      <td>100.0</td>\n    </tr>\n    <tr>\n      <th>51182</th>\n      <td>51182</td>\n      <td>Emily Post's Etiquette</td>\n      <td>features twenty new chapters that cover such a...</td>\n      <td>Peggy Post, Emily Post</td>\n      <td>['Nonfiction', 'Reference', 'Self Help', 'Clas...</td>\n      <td>95.0</td>\n    </tr>\n    <tr>\n      <th>44637</th>\n      <td>44637</td>\n      <td>The Liberation of Gabriel King</td>\n      <td>gabriel king was a born chicken hes afraid of ...</td>\n      <td>K.L. Going (Goodreads Author)</td>\n      <td>['Historical Fiction', 'Young Adult', 'Fiction...</td>\n      <td>94.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":" def getSGRAMEmbeddingList(preprocessed_sentences):\n    w2v_embeddings = []\n    for i in range(len(preprocessed_sentences)):\n        for j in range(len(preprocessed_sentences[i])):\n            if j == 0:\n                test = np.zeros(100)\n                test += SGRAM.wv[preprocessed_sentences[i][j]]\n            else:\n                test += SGRAM.wv[preprocessed_sentences[i][j]]\n        test/=len(preprocessed_sentences[i])\n        w2v_embeddings.append(test)\n    return w2v_embeddings\nw2v_embeddings = getSGRAMEmbeddingList(preprocessed_sentences)","metadata":{"execution":{"iopub.status.busy":"2023-04-27T07:55:09.240178Z","iopub.execute_input":"2023-04-27T07:55:09.240698Z","iopub.status.idle":"2023-04-27T07:55:25.571002Z","shell.execute_reply.started":"2023-04-27T07:55:09.240652Z","shell.execute_reply":"2023-04-27T07:55:25.569894Z"},"trusted":true},"execution_count":121,"outputs":[]},{"cell_type":"code","source":"recommended_books = findRecommendationW2V(w2v_embeddings)\nrecommended_books","metadata":{"execution":{"iopub.status.busy":"2023-04-27T07:58:16.375810Z","iopub.execute_input":"2023-04-27T07:58:16.376897Z","iopub.status.idle":"2023-04-27T07:58:18.194421Z","shell.execute_reply.started":"2023-04-27T07:58:16.376853Z","shell.execute_reply":"2023-04-27T07:58:18.193106Z"},"trusted":true},"execution_count":124,"outputs":[{"name":"stdout","text":"index         6431.000000\ncosine_sim       0.991712\nName: 6431, dtype: float64\n","output_type":"stream"},{"execution_count":124,"output_type":"execute_result","data":{"text/plain":"       index                                     title  \\\n26285  26762                           রূপের ডালি খেলা   \n6431    6472        The Ballad of Songbirds and Snakes   \n26735  27227                              Pandeymonium   \n13463  13571                 A Plague Upon Your Family   \n42664  43742  The Zombie Chasers #7: World Zombination   \n18400  18584                                     Union   \n19318  19531                 Sleepeth Not, the Bastard   \n8305    8355                         The Quillan Games   \n3992    4013                                  Sleepers   \n11325  11403                                  Outcaste   \n\n                                             description  \\\n26285  বীরব্রতী ভাসিয়া\\nরূপের ডালি খেলা\\nপাশা সেদভের ...   \n6431   it is the morning of the reaping that will kic...   \n26735  what makes piyush pandey an extraordinary adve...   \n13463  this story picks up exactly where book one lef...   \n42664  in the final book in the beloved zombie chaser...   \n18400  there are no holes in space none to hide in no...   \n19318  the gravity of fate is nothing in comparison t...   \n8305   let the games beginquillan is a territory on t...   \n3992   sleeper colloq 1 outoftown hit man who spends ...   \n11325  rahel sayana is desperate to escape the life h...   \n\n                                                  author  \\\n26285  U. Yakovlev, Noni Bhowmik (translator), ভ. ইলি...   \n6431                                     Suzanne Collins   \n26735                                      Piyush Pandey   \n13463                       Mark Tufo (Goodreads Author)   \n42664       John Kloepfer, David DeGrand (Illustrations)   \n18400               Jolea M. Harrison (Goodreads Author)   \n19318                    Dave Matthes (Goodreads Author)   \n8305                     D.J. MacHale (Goodreads Author)   \n3992                                  Lorenzo Carcaterra   \n11325               Fletcher DeLancey (Goodreads Author)   \n\n                                                  genres  likedPercent  \n26285                     ['Childrens', 'Short Stories']          95.0  \n6431   ['Young Adult', 'Dystopia', 'Fiction', 'Fantas...          90.0  \n26735            ['Nonfiction', 'Biography', 'Business']          90.0  \n13463  ['Zombies', 'Horror', 'Post Apocalyptic', 'Aud...          96.0  \n42664                                        ['Zombies']          97.0  \n18400                                                 []          98.0  \n19318                                                 []         100.0  \n8305   ['Fantasy', 'Young Adult', 'Science Fiction', ...          96.0  \n3992   ['Fiction', 'Crime', 'True Crime', 'Thriller',...          97.0  \n11325  ['Science Fiction', 'Fantasy', 'LGBT', 'Lesbia...         100.0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>title</th>\n      <th>description</th>\n      <th>author</th>\n      <th>genres</th>\n      <th>likedPercent</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>26285</th>\n      <td>26762</td>\n      <td>রূপের ডালি খেলা</td>\n      <td>বীরব্রতী ভাসিয়া\\nরূপের ডালি খেলা\\nপাশা সেদভের ...</td>\n      <td>U. Yakovlev, Noni Bhowmik (translator), ভ. ইলি...</td>\n      <td>['Childrens', 'Short Stories']</td>\n      <td>95.0</td>\n    </tr>\n    <tr>\n      <th>6431</th>\n      <td>6472</td>\n      <td>The Ballad of Songbirds and Snakes</td>\n      <td>it is the morning of the reaping that will kic...</td>\n      <td>Suzanne Collins</td>\n      <td>['Young Adult', 'Dystopia', 'Fiction', 'Fantas...</td>\n      <td>90.0</td>\n    </tr>\n    <tr>\n      <th>26735</th>\n      <td>27227</td>\n      <td>Pandeymonium</td>\n      <td>what makes piyush pandey an extraordinary adve...</td>\n      <td>Piyush Pandey</td>\n      <td>['Nonfiction', 'Biography', 'Business']</td>\n      <td>90.0</td>\n    </tr>\n    <tr>\n      <th>13463</th>\n      <td>13571</td>\n      <td>A Plague Upon Your Family</td>\n      <td>this story picks up exactly where book one lef...</td>\n      <td>Mark Tufo (Goodreads Author)</td>\n      <td>['Zombies', 'Horror', 'Post Apocalyptic', 'Aud...</td>\n      <td>96.0</td>\n    </tr>\n    <tr>\n      <th>42664</th>\n      <td>43742</td>\n      <td>The Zombie Chasers #7: World Zombination</td>\n      <td>in the final book in the beloved zombie chaser...</td>\n      <td>John Kloepfer, David DeGrand (Illustrations)</td>\n      <td>['Zombies']</td>\n      <td>97.0</td>\n    </tr>\n    <tr>\n      <th>18400</th>\n      <td>18584</td>\n      <td>Union</td>\n      <td>there are no holes in space none to hide in no...</td>\n      <td>Jolea M. Harrison (Goodreads Author)</td>\n      <td>[]</td>\n      <td>98.0</td>\n    </tr>\n    <tr>\n      <th>19318</th>\n      <td>19531</td>\n      <td>Sleepeth Not, the Bastard</td>\n      <td>the gravity of fate is nothing in comparison t...</td>\n      <td>Dave Matthes (Goodreads Author)</td>\n      <td>[]</td>\n      <td>100.0</td>\n    </tr>\n    <tr>\n      <th>8305</th>\n      <td>8355</td>\n      <td>The Quillan Games</td>\n      <td>let the games beginquillan is a territory on t...</td>\n      <td>D.J. MacHale (Goodreads Author)</td>\n      <td>['Fantasy', 'Young Adult', 'Science Fiction', ...</td>\n      <td>96.0</td>\n    </tr>\n    <tr>\n      <th>3992</th>\n      <td>4013</td>\n      <td>Sleepers</td>\n      <td>sleeper colloq 1 outoftown hit man who spends ...</td>\n      <td>Lorenzo Carcaterra</td>\n      <td>['Fiction', 'Crime', 'True Crime', 'Thriller',...</td>\n      <td>97.0</td>\n    </tr>\n    <tr>\n      <th>11325</th>\n      <td>11403</td>\n      <td>Outcaste</td>\n      <td>rahel sayana is desperate to escape the life h...</td>\n      <td>Fletcher DeLancey (Goodreads Author)</td>\n      <td>['Science Fiction', 'Fantasy', 'LGBT', 'Lesbia...</td>\n      <td>100.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# **FIND EMBEDDINGS FOR TRANSFORMERS**","metadata":{}},{"cell_type":"code","source":"# data = np.array(data).tolist()\n# data[22404]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# textBeautified = []\n# for i in range(len(input_dataframe)):\n#     sentence = \" \"\n#     sentence += \"Description of the book is - \" + str(input_dataframe.iloc[i][\"description\"])\n#     sentence += \". \"\n#     sentence += \"The author of the book is - \" + input_dataframe.iloc[i][\"author\"]\n#     sentence += \". \"\n#     sentence += \"The genres of the book are - \"\n#     sentence +=  input_dataframe.iloc[i][\"genres\"][1:-2]\n#     sentence += \". \"\n#     sentence += \"The rating of the book is - \" + str(input_dataframe.iloc[i][\"likedPercent\"])\n#     textBeautified.append(sentence)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# data = textBeautified\n# def get_embeddings(text):\n#     return model.encode(text, device = device)\n# embeddings = get_embeddings(data)\n# np.save('D-embeddings', embeddings)\n# data = data.iloc[:15000]\n# temp1 = data.progress_apply(get_embeddings)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **TRANSFORMER BASED RECOMMENDATION**\nRecommends similar books for each book individually.\nRecommends based context of both books read'","metadata":{}},{"cell_type":"code","source":"def getSimilarityDescriptionScores(description = text.iloc[1733]):\n    test_embedding = model.encode(description, device = device)\n    similarity = []\n    for i in finalDescriptionEmbeddings['embeddings']:\n        similarity.append(-1*(spatial.distance.cosine(i, test_embedding)-1))\n    finalDescriptionEmbeddings['cosine_sim'] = similarity\n    result = finalDescriptionEmbeddings.sort_values(by=['cosine_sim'], ascending = False)\n    return result","metadata":{"execution":{"iopub.status.busy":"2023-05-07T18:17:52.935682Z","iopub.status.idle":"2023-05-07T18:17:52.936888Z","shell.execute_reply.started":"2023-05-07T18:17:52.936590Z","shell.execute_reply":"2023-05-07T18:17:52.936619Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def getSimilarityScores(description = text.iloc[1733]):\n    test_embedding = model.encode(description, device = device)\n    similarity = []\n    for i in finalAllDescriptionEmbeddings['embeddings']:\n        similarity.append(-1*(spatial.distance.cosine(i, test_embedding)-1))\n    finalAllDescriptionEmbeddings['cosine_sim'] = similarity\n    result = finalAllDescriptionEmbeddings.sort_values(by=['cosine_sim'], ascending = False)\n    return result","metadata":{"execution":{"iopub.status.busy":"2023-05-07T18:17:52.938326Z","iopub.status.idle":"2023-05-07T18:17:52.939250Z","shell.execute_reply.started":"2023-05-07T18:17:52.938969Z","shell.execute_reply":"2023-05-07T18:17:52.938995Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def becauseYouLiked(liked_books_description):\n    recommend_books = []\n    for liked_book in liked_books_description:\n        fin = getSimilarityScores(liked_book)\n        recommend_books.append(input_dataframe.iloc[int(fin.iloc[1]['index'])])\n        recommend_books.append(input_dataframe.iloc[int(fin.iloc[2]['index'])])\n        recommend_books.append(input_dataframe.iloc[int(fin.iloc[3]['index'])])\n        recommend_books.append(input_dataframe.iloc[int(fin.iloc[4]['index'])])\n        recommend_books.append(input_dataframe.iloc[int(fin.iloc[5]['index'])])\n        recommend_books.append(input_dataframe.iloc[int(fin.iloc[6]['index'])])\n    recommend_books = pd.DataFrame(recommend_books)\n    return recommend_books\n# recommended_books = becauseYouLiked(liked_book_descriptionAll)\n# recommended_books","metadata":{"execution":{"iopub.status.busy":"2023-05-07T18:17:52.940818Z","iopub.status.idle":"2023-05-07T18:17:52.941714Z","shell.execute_reply.started":"2023-05-07T18:17:52.941425Z","shell.execute_reply":"2023-05-07T18:17:52.941451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def becauseYouLikedDescription(liked_books_description):\n    recommend_books = []\n    for liked_book in liked_books_description:\n        fin = getSimilarityDescriptionScores(liked_book)\n        recommend_books.append(input_dataframe.iloc[int(fin.iloc[1]['index'])])\n        recommend_books.append(input_dataframe.iloc[int(fin.iloc[2]['index'])])\n        recommend_books.append(input_dataframe.iloc[int(fin.iloc[3]['index'])])\n        recommend_books.append(input_dataframe.iloc[int(fin.iloc[4]['index'])])\n        recommend_books.append(input_dataframe.iloc[int(fin.iloc[5]['index'])])\n        recommend_books.append(input_dataframe.iloc[int(fin.iloc[6]['index'])])\n    recommend_books = pd.DataFrame(recommend_books)\n    return recommend_books\n# recommended_books = becauseYouLikedDescription(liked_book_description)\n# recommended_books","metadata":{"execution":{"iopub.status.busy":"2023-05-07T18:17:52.943238Z","iopub.status.idle":"2023-05-07T18:17:52.944119Z","shell.execute_reply.started":"2023-05-07T18:17:52.943854Z","shell.execute_reply":"2023-05-07T18:17:52.943881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def youMayAlsoLike(liked_book_description):\n    combined_input = \"\"\n    for liked_book in liked_book_description:\n        combined_input += liked_book\n        combined_input += \"\\n\"\n    similarity = []\n    test_embedding = model.encode(combined_input, device = device)\n    for book_embeddings in finalDescriptionEmbeddings['embeddings']:\n        similarity.append(-1*(spatial.distance.cosine(book_embeddings, test_embedding)-1))\n    finalDescriptionEmbeddings['cosine_sim'] = similarity\n    result = finalDescriptionEmbeddings.sort_values(by=['cosine_sim'], ascending = False)\n    contextBasedPrediction = []\n    contextBasedPrediction.append(input_dataframe.iloc[result.iloc[1][0]])\n    contextBasedPrediction.append(input_dataframe.iloc[result.iloc[2][0]])\n    contextBasedPrediction.append(input_dataframe.iloc[result.iloc[3][0]])\n    contextBasedPrediction.append(input_dataframe.iloc[result.iloc[4][0]])\n    contextBasedPrediction.append(input_dataframe.iloc[result.iloc[5][0]])\n    contextBasedPrediction.append(input_dataframe.iloc[result.iloc[6][0]])\n    contextBasedPrediction.append(input_dataframe.iloc[result.iloc[7][0]])\n    contextBasedPrediction.append(input_dataframe.iloc[result.iloc[8][0]])\n    contextBasedPrediction.append(input_dataframe.iloc[result.iloc[9][0]])\n    contextBasedPrediction.append(input_dataframe.iloc[result.iloc[10][0]])\n    contextBasedPrediction.append(input_dataframe.iloc[result.iloc[11][0]])\n    contextBasedPrediction = pd.DataFrame(contextBasedPrediction)\n    return contextBasedPrediction\n\n# contextBasedPrediction = youMayAlsoLike(liked_book_description)\n# contextBasedPrediction","metadata":{"execution":{"iopub.status.busy":"2023-05-07T18:17:52.945726Z","iopub.status.idle":"2023-05-07T18:17:52.946835Z","shell.execute_reply.started":"2023-05-07T18:17:52.946538Z","shell.execute_reply":"2023-05-07T18:17:52.946572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def youMayAlsoLikeAveraged(liked_book_description):\n    combined_input = \"\"\n    count = 0\n    for liked_book in liked_book_description:\n        if count == 0:\n            test_embedding = np.zeros(768)\n            test_embedding += model.encode(liked_book, device = device)\n        count+=1\n    test_embedding /= count\n    similarity = []\n    for book_embeddings in finalDescriptionEmbeddings['embeddings']:\n        similarity.append(-1*(spatial.distance.cosine(book_embeddings, test_embedding)-1))\n    finalDescriptionEmbeddings['cosine_sim'] = similarity\n    result = finalDescriptionEmbeddings.sort_values(by=['cosine_sim'], ascending = False)\n    contextBasedPrediction = []\n    contextBasedPrediction.append(input_dataframe.iloc[result.iloc[1][0]])\n    contextBasedPrediction.append(input_dataframe.iloc[result.iloc[2][0]])\n    contextBasedPrediction.append(input_dataframe.iloc[result.iloc[3][0]])\n    contextBasedPrediction.append(input_dataframe.iloc[result.iloc[4][0]])\n    contextBasedPrediction.append(input_dataframe.iloc[result.iloc[5][0]])\n    contextBasedPrediction.append(input_dataframe.iloc[result.iloc[6][0]])\n    contextBasedPrediction.append(input_dataframe.iloc[result.iloc[7][0]])\n    contextBasedPrediction.append(input_dataframe.iloc[result.iloc[8][0]])\n    contextBasedPrediction.append(input_dataframe.iloc[result.iloc[9][0]])\n    contextBasedPrediction.append(input_dataframe.iloc[result.iloc[10][0]])\n    contextBasedPrediction = pd.DataFrame(contextBasedPrediction)\n    return contextBasedPrediction\n\n# contextBasedPrediction = youMayAlsoLikeAveraged(liked_book_description)\n# contextBasedPrediction","metadata":{"execution":{"iopub.status.busy":"2023-05-07T18:17:52.948575Z","iopub.status.idle":"2023-05-07T18:17:52.949065Z","shell.execute_reply.started":"2023-05-07T18:17:52.948813Z","shell.execute_reply":"2023-05-07T18:17:52.948837Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def getSimilarityDescriptionBScores(description = text.iloc[1733]):\n    test_embedding = model.encode(description, device = device)\n    similarity = []\n    for i in finalBeautifiedEmbeddings['embeddings']:\n        similarity.append(-1*(spatial.distance.cosine(i, test_embedding)-1))\n    finalBeautifiedEmbeddings['cosine_sim'] = similarity\n    result = finalBeautifiedEmbeddings.sort_values(by=['cosine_sim'], ascending = False)\n    return result\n\ndef becauseYouLikedBeautifiedDescription(liked_books_description):\n    recommend_books = []\n    for liked_book in liked_books_description['description']:\n        print(liked_book)\n        fin = getSimilarityDescriptionBScores(liked_book)\n        recommend_books.append(input_dataframe.iloc[int(fin.iloc[1]['index'])])\n        recommend_books.append(input_dataframe.iloc[int(fin.iloc[2]['index'])])\n        recommend_books.append(input_dataframe.iloc[int(fin.iloc[3]['index'])])\n        recommend_books.append(input_dataframe.iloc[int(fin.iloc[4]['index'])])\n        recommend_books.append(input_dataframe.iloc[int(fin.iloc[5]['index'])])\n        recommend_books.append(input_dataframe.iloc[int(fin.iloc[6]['index'])])\n        recommend_books.append(input_dataframe.iloc[int(fin.iloc[7]['index'])])\n        recommend_books.append(input_dataframe.iloc[int(fin.iloc[8]['index'])])\n        recommend_books.append(input_dataframe.iloc[int(fin.iloc[9]['index'])])\n        recommend_books.append(input_dataframe.iloc[int(fin.iloc[10]['index'])])    \n    recommend_books = pd.DataFrame(recommend_books)\n    return recommend_books\n# recommended_books = becauseYouLikedBeautifiedDescription(liked_book_descriptionBeauty)\n# recommended_books","metadata":{"execution":{"iopub.status.busy":"2023-05-07T18:17:52.950816Z","iopub.status.idle":"2023-05-07T18:17:52.952950Z","shell.execute_reply.started":"2023-05-07T18:17:52.952618Z","shell.execute_reply":"2023-05-07T18:17:52.952646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def youMayAlsoLikeAveragedB(liked_book_description):\n    combined_input = \"\"\n    count = 0\n    for liked_book in liked_book_description:\n        if count == 0:\n            test_embedding = np.zeros(768)\n            test_embedding += model.encode(liked_book, device = device)\n        count+=1\n    test_embedding /= count\n    similarity = []\n    for book_embeddings in finalBeautifiedEmbeddings['embeddings']:\n        similarity.append(-1*(spatial.distance.cosine(book_embeddings, test_embedding)-1))\n    finalBeautifiedEmbeddings['cosine_sim'] = similarity\n    result = finalBeautifiedEmbeddings.sort_values(by=['cosine_sim'], ascending = False)\n    contextBasedPrediction = []\n    contextBasedPrediction.append(input_dataframe.iloc[result.iloc[1][0]])\n    contextBasedPrediction.append(input_dataframe.iloc[result.iloc[2][0]])\n    contextBasedPrediction.append(input_dataframe.iloc[result.iloc[3][0]])\n    contextBasedPrediction.append(input_dataframe.iloc[result.iloc[4][0]])\n    contextBasedPrediction.append(input_dataframe.iloc[result.iloc[5][0]])\n    contextBasedPrediction.append(input_dataframe.iloc[result.iloc[6][0]])\n    contextBasedPrediction.append(input_dataframe.iloc[result.iloc[7][0]])\n    contextBasedPrediction.append(input_dataframe.iloc[result.iloc[8][0]])\n    contextBasedPrediction.append(input_dataframe.iloc[result.iloc[9][0]])\n    contextBasedPrediction.append(input_dataframe.iloc[result.iloc[10][0]])\n    contextBasedPrediction = pd.DataFrame(contextBasedPrediction)\n    return contextBasedPrediction\n\n# contextBasedPrediction = youMayAlsoLikeAveragedB(liked_book_descriptionBeauty['description'])\n# contextBasedPrediction","metadata":{"execution":{"iopub.status.busy":"2023-05-07T18:17:52.954429Z","iopub.status.idle":"2023-05-07T18:17:52.955737Z","shell.execute_reply.started":"2023-05-07T18:17:52.955409Z","shell.execute_reply":"2023-05-07T18:17:52.955436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def youMayAlsoLikeB(liked_book_description):\n    combined_input = \"\"\n    for liked_book in liked_book_description:\n        combined_input += liked_book\n        combined_input += \"\\n\"\n    similarity = []\n    test_embedding = model.encode(combined_input, device = device)\n    for book_embeddings in finalBeautifiedEmbeddings['embeddings']:\n        similarity.append(-1*(spatial.distance.cosine(book_embeddings, test_embedding)-1))\n    finalBeautifiedEmbeddings['cosine_sim'] = similarity\n    result =finalBeautifiedEmbeddings.sort_values(by=['cosine_sim'], ascending = False)\n    contextBasedPrediction = []\n    contextBasedPrediction.append(input_dataframe.iloc[result.iloc[1][0]])\n    contextBasedPrediction.append(input_dataframe.iloc[result.iloc[2][0]])\n    contextBasedPrediction.append(input_dataframe.iloc[result.iloc[3][0]])\n    contextBasedPrediction.append(input_dataframe.iloc[result.iloc[4][0]])\n    contextBasedPrediction.append(input_dataframe.iloc[result.iloc[5][0]])\n    contextBasedPrediction.append(input_dataframe.iloc[result.iloc[6][0]])\n    contextBasedPrediction.append(input_dataframe.iloc[result.iloc[7][0]])\n    contextBasedPrediction.append(input_dataframe.iloc[result.iloc[8][0]])\n    contextBasedPrediction.append(input_dataframe.iloc[result.iloc[9][0]])\n    contextBasedPrediction.append(input_dataframe.iloc[result.iloc[10][0]])\n    contextBasedPrediction = pd.DataFrame(contextBasedPrediction)\n    return contextBasedPrediction\n\n# contextBasedPrediction = youMayAlsoLikeB(liked_book_descriptionBeauty['description'])\n# contextBasedPrediction","metadata":{"execution":{"iopub.status.busy":"2023-05-07T18:17:52.957286Z","iopub.status.idle":"2023-05-07T18:17:52.958265Z","shell.execute_reply.started":"2023-05-07T18:17:52.957970Z","shell.execute_reply":"2023-05-07T18:17:52.957998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **User input for recommendations**","metadata":{}},{"cell_type":"code","source":"# newUser = False\nlengthy = False\ngenre = []\nlikedBooks_title = []\nlikedBooks_data=[]\ndef StartReccSystem():\n    global newUser, lengthy, genre, likedBooks\n    print(\"Welcome to Book Recommender System\\n\")\n    \n    userinput = input(\"Do you have a prior reading experience (Y/n)?\")\n    if userinput.lower() == 'y':\n        newUser = True\n        likedBooks = input(\"Enter the title of books that you liked the most (separated by semicolon)\").split(sep=';')\n    elif userinput.lower() == 'n':\n        newUser = False\n        genre = input(\"Enter the genres you are interested in (separated by semicolon): \").split(sep=';')\n    \n    if (input(\"Are you interested in reading lenghty books (Y/n)?\").lower() == 'y'):\n        lengthy = True\n    else:\n        lengthy = False","metadata":{"execution":{"iopub.status.busy":"2023-05-07T18:18:15.843887Z","iopub.execute_input":"2023-05-07T18:18:15.844965Z","iopub.status.idle":"2023-05-07T18:18:15.853591Z","shell.execute_reply.started":"2023-05-07T18:18:15.844919Z","shell.execute_reply":"2023-05-07T18:18:15.852121Z"},"trusted":true},"execution_count":158,"outputs":[]},{"cell_type":"code","source":"def getRecommedation_NewReader():\n    ## Finding the top 5 books for each genre available\n    main_df = input_dataframe\n    genreDict = dict()          ## Top 5 book title per genre\n    ratingList = dict()         ## Top 5 rating per genre\n    lowest = 5\n    for row in range(len(main_df)):\n        genre = main_df.loc[row, \"genres\"]\n        for g in genre:\n            if g in genreDict:\n                if len(genreDict[g]) < 5:\n                    genreDict[g].append(main_df[\"title\"][row])\n                    ratingList[g].append(main_df[\"rating\"][row])\n                    sorted(ratingList[g], reverse=True)\n                else:\n                    if main_df[\"rating\"][row] > ratingList[g][4] and main_df[\"numRatings\"][row] > 1000:\n                        genreDict[g][4] = main_df[\"title\"][row]\n                        ratingList[g][4] = main_df[\"rating\"][row]\n                        sorted(ratingList[g], reverse=True)\n            else:\n                genreDict[g] = []\n                ratingList[g] = []\n                genreDict[g].append(main_df[\"title\"][row])\n                ratingList[g].append(main_df[\"rating\"][row])\n    ","metadata":{"execution":{"iopub.status.busy":"2023-05-07T18:18:16.032056Z","iopub.execute_input":"2023-05-07T18:18:16.032596Z","iopub.status.idle":"2023-05-07T18:18:16.052036Z","shell.execute_reply.started":"2023-05-07T18:18:16.032548Z","shell.execute_reply":"2023-05-07T18:18:16.050699Z"},"trusted":true},"execution_count":159,"outputs":[]},{"cell_type":"code","source":"def getBooks(likedBooks=['Diary of a Wimpy Kid']):\n    for i in range(len(likedBooks)):\n        book_name = likedBooks[i]\n        print(book_name)\n        driver.get(\"https://www.goodreads.com/\")\n        WebDriverWait(driver, 20).until(EC.element_to_be_clickable((By.XPATH, \"//input[@id='sitesearch_field']\"))).send_keys(book_name + Keys.RETURN)\n        driver.implicitly_wait(10)  \n        element = driver.find_element(By.XPATH, \"//a[@class='bookTitle']\")\n        driver.execute_script(\"arguments[0].click();\", element)\n\n        # WebDriverWait(driver, 20).until(EC.element_to_be_clickable((By.XPATH, \"//a[@class='bookTitle']\"))).click()\n        cur_url = str(driver.current_url)\n        # print(cur_url)\n        url = cur_url.split('?')[0]\n        print(url)\n        # driver.get(url)\n\n        driver.implicitly_wait(10)  \n        element = driver.find_element(By.XPATH, '//span[contains(text(),\"Book details & editions\")]')\n        driver.execute_script(\"arguments[0].click();\", element)\n        element = driver.find_element(By.XPATH, '//span[contains(text(),\"Show more\")]')\n        driver.execute_script(\"arguments[0].click();\", element)\n        element = driver.find_element(By.XPATH, '//span[contains(text(),\"Show more\")]')\n        driver.execute_script(\"arguments[0].click();\", element)\n        element = driver.find_element(By.XPATH, '//span[contains(text(),\"...more\")]')\n        driver.execute_script(\"arguments[0].click();\", element)\n\n        # Get the html page content from the driver\n        content = driver.page_source\n\n        # Parse the HTML content using BeautifulSoup\n        book_soup = BeautifulSoup(content, 'html.parser')\n        # print(soup.prettify())\n        #################################### Extract the book details#######################################\n        # Extract book id \n        match = re.search(r\"\\d+\", cur_url)\n        if match:\n            book_id = match.group()\n        else: book_id=\"\"\n        # Extract book title\n        book_title=book_soup.find('h1', {'data-testid': 'bookTitle'}).text.strip()\n        print(book_title)\n\n        # Extract book description\n        book_description = book_soup.find_all('div', class_='DetailsLayoutRightParagraph__widthConstrained')[0].text.strip()\n        # print(book_description)\n\n        # Extract book generes\n        genre = book_soup.find_all('span', class_='BookPageMetadataSection__genreButton')\n        genres=[]\n        for i in range(len(genre)):\n            genres.append(genre[i].text.strip())\n        # print(genres)\n\n        # Extract book author\n        book_author = book_soup.find_all('span', class_='ContributorLink__name')[0].text.strip() \n        # print(book_author)\n\n        #Extract num of ratings\n        num_ratings=book_soup.find('span', {'data-testid':\"ratingsCount\"}).text.strip()[:-8].replace(\",\", \"\")\n        # print(num_ratings)\n\n        # Extract number of book pages\n        num_pages = book_soup.find('p', {'data-testid':\"pagesFormat\"}).text.strip().split(\",\")[0]\n        # print(num_pages)\n\n        # Extract first published date\n        first_published = book_soup.find('p', {'data-testid':\"publicationInfo\"}).text.strip()[16:]\n        # print(first_published)\n\n        # Extract book awards\n        try:\n            awards = book_soup.find_all(\"span\", {\"data-testid\": \"award\"})\n            book_awards=[]\n            for i in range(len(awards)):\n                book_awards.append(awards[i].text.strip())\n        except AttributeError:\n            book_awards=[]\n        # print(book_awards)\n\n        # Extract book series\n        try:\n            book_series = book_soup.find('h3', {'class':'Text Text__title3 Text__italic Text__regular Text__subdued'}).text.strip()\n        except AttributeError:\n            book_series=\"\"\n        # print(book_series)\n\n        # Extract book avg rating\n        avg_rating = book_soup.find('div', {'class':'RatingStatistics__rating'}).text.strip()\n        # print(avg_rating)\n\n        # Extract book individuak ratings\n        ratingsByStars=[]\n        ratingsByStars.append(book_soup.find('div', {'data-testid':\"labelTotal-5\",'class':'RatingsHistogram__labelTotal'}).text.strip().split(\" \")[0].replace(\",\",\"\"))\n        ratingsByStars.append(book_soup.find('div', {'data-testid':\"labelTotal-4\",'class':'RatingsHistogram__labelTotal'}).text.strip().split(\" \")[0].replace(\",\",\"\"))\n        ratingsByStars.append(book_soup.find('div', {'data-testid':\"labelTotal-3\",'class':'RatingsHistogram__labelTotal'}).text.strip().split(\" \")[0].replace(\",\",\"\"))\n        ratingsByStars.append(book_soup.find('div', {'data-testid':\"labelTotal-2\",'class':'RatingsHistogram__labelTotal'}).text.strip().split(\" \")[0].replace(\",\",\"\"))\n        ratingsByStars.append(book_soup.find('div', {'data-testid':\"labelTotal-1\",'class':'RatingsHistogram__labelTotal'}).text.strip().split(\" \")[0].replace(\",\",\"\"))\n        # print(ratingsByStars)\n        #Append the book data to the list\n        likedBooks_data.append([book_id, book_title,book_series,book_author, avg_rating, book_description, genres, num_pages, first_published, book_awards, num_ratings, ratingsByStars])\n    ","metadata":{"execution":{"iopub.status.busy":"2023-05-07T18:18:16.191187Z","iopub.execute_input":"2023-05-07T18:18:16.191686Z","iopub.status.idle":"2023-05-07T18:18:16.216054Z","shell.execute_reply.started":"2023-05-07T18:18:16.191632Z","shell.execute_reply":"2023-05-07T18:18:16.214551Z"},"trusted":true},"execution_count":160,"outputs":[]},{"cell_type":"code","source":"if newUser==False:\n    strings = []   # create an empty list to store the user input strings\n    n = int(input(\"How many strings do you want to enter? \"))\n\n    for i in range(n):\n        s = input(\"Enter string {}: \".format(i+1))\n        strings.append(s)\n    print(\"The strings you entered are: \", strings)\n    print(strings)\n    getBooks(strings)\nelse:\n    getRecommedation_NewReader()","metadata":{"execution":{"iopub.status.busy":"2023-05-07T18:18:16.355012Z","iopub.execute_input":"2023-05-07T18:18:16.355322Z","iopub.status.idle":"2023-05-07T18:18:31.541042Z","shell.execute_reply.started":"2023-05-07T18:18:16.355294Z","shell.execute_reply":"2023-05-07T18:18:31.539724Z"},"trusted":true},"execution_count":161,"outputs":[{"output_type":"stream","name":"stdin","text":"How many strings do you want to enter?  1\nEnter string 1:  The martian\n"},{"name":"stdout","text":"The strings you entered are:  ['The martian']\n['The martian']\nThe martian\nhttps://www.goodreads.com/book/show/18007564-the-martian\nThe Martian\n","output_type":"stream"}]},{"cell_type":"code","source":"# Create a dataframe from the list of book data and save it to a csv file\nbooks_df = pd.DataFrame(likedBooks_data, columns=['id', 'title','series','author', 'ratings', 'description', 'genres', 'num_pages', 'first_published', 'awards', 'num_ratings', 'ratingsByStars'])\nbooks_df.to_csv('UserBooks.csv', index=False, encoding='utf-8')\n# driver.close()\ninput_dataframe = input_dataframe.loc[:, [\"title\",\"description\", \"author\", \"genres\", \"likedPercent\"]]\ninput_dataframe = input_dataframe.reset_index()\nbooks_df = books_df.loc[:, [\"title\", \"description\", \"author\", \"genres\", \"ratings\"]]\n\ndef convertPercent(text):\n    temp = float(text)\n    likedPercent = temp/5*100\n    text = likedPercent\n    return text\nbooks_df.ratings = books_df.ratings.apply(convertPercent)\ninput_dataframe = preprocess(input_dataframe)\nbooks_df = preprocess(books_df)\nliked_book_description = getText(books_df)","metadata":{"execution":{"iopub.status.busy":"2023-05-07T18:18:31.543934Z","iopub.execute_input":"2023-05-07T18:18:31.544986Z","iopub.status.idle":"2023-05-07T18:18:34.850998Z","shell.execute_reply.started":"2023-05-07T18:18:31.544941Z","shell.execute_reply":"2023-05-07T18:18:34.849805Z"},"trusted":true},"execution_count":162,"outputs":[]},{"cell_type":"markdown","source":"**NOTE - Since we have already proved in our presentation that the word2vec model is not as good as the transformers model, we work with transformer models here. Out of which we are showing the best results only. (As discussed in the presentation)**","metadata":{}},{"cell_type":"code","source":"def makeRecommendations(liked_book_description):\n    \n    #OTHER TRANSFORMER BASED RECOMMENDATION MODEL OUTPUTS -\n    #     print(\"Reccomending for best books which are similar to each books(individually) in the list: \")\n    #     print(\"\\n\\n\")\n    #     print(\"Reccomending similar books wrt genres,author,description and ratings\")\n    #     result_df=becauseYouLikedBeautifiedDescription(liked_book_description)\n    #     # print(result_df)\n    #     print(\"\\n\\n\")\n    #     print(\"Reccomending similar books wrt only description\")\n    #     result_df=becauseYouLikedDescription(liked_book_description)\n    #     # print(result_df)\n    #     print(\"Reccomending similar books wrt genres,author,description\")\n    #     result_df=becauseYouLiked(liked_book_description)\n    #     # print(result_df)\n    #     print(\"\\n\\n\")\n\n    #     print(\"**************************************************************************************************************\")\n    #     print(\"**************************************************************************************************************\")\n    #     print(\"**************************************************************************************************************\")\n    #     print(\"Reccomending for best books which are similar to all books(combined) in the list\")\n    \n    \n    print(\"Reccomending similar books wrt genres,author,description,ratings\")\n    print(\"Average of all the embeddings of the books in the userlist is taken and then cosine similarity is calculated with all the books in the dataset\")\n    result_dfAvg= youMayAlsoLikeAveragedB(liked_book_description)\n    # print(result_df)\n    print(\"\\n\\n\")\n\n    print(\"Concatenate all the embeddings of the books in the userlist and then cosine similarity is calculated with all the books in the dataset\")\n    result_df= youMayAlsoLikeB(liked_book_description)\n    # print(result_df)\n    print(\"\\n\\n\")\n    return result_df, result_dfAvg","metadata":{"execution":{"iopub.status.busy":"2023-05-07T18:18:34.857590Z","iopub.execute_input":"2023-05-07T18:18:34.859931Z","iopub.status.idle":"2023-05-07T18:18:34.869789Z","shell.execute_reply.started":"2023-05-07T18:18:34.859892Z","shell.execute_reply":"2023-05-07T18:18:34.868421Z"},"trusted":true},"execution_count":163,"outputs":[]},{"cell_type":"code","source":"result, resultAvg = makeRecommendations(liked_book_description)\nresult.head()","metadata":{"execution":{"iopub.status.busy":"2023-05-07T18:18:34.875732Z","iopub.execute_input":"2023-05-07T18:18:34.878533Z","iopub.status.idle":"2023-05-07T18:18:47.490540Z","shell.execute_reply.started":"2023-05-07T18:18:34.878495Z","shell.execute_reply":"2023-05-07T18:18:47.489225Z"},"trusted":true},"execution_count":164,"outputs":[{"name":"stdout","text":"Reccomending similar books wrt genres,author,description,ratings\nAverage of all the embeddings of the books in the userlist is taken and then cosine similarity is calculated with all the books in the dataset\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3340471823094489941d42886b75a67e"}},"metadata":{}},{"name":"stdout","text":"\n\n\nConcatenate all the embeddings of the books in the userlist and then cosine similarity is calculated with all the books in the dataset\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4ee6024fc7bc4b8aaf8531e1cd9cc234"}},"metadata":{}},{"name":"stdout","text":"\n\n\n","output_type":"stream"},{"execution_count":164,"output_type":"execute_result","data":{"text/plain":"       index                   title  \\\n385      386  The Martian Chronicles   \n12563  12661              Red Planet   \n18400  18584                   Union   \n28632  29183     Planet of Adventure   \n38035  38950                 Deepsix   \n\n                                             description  \\\n385    the strange and wonderful tale of man’s experi...   \n12563  jim marlow and his strangelooking martian frie...   \n18400  there are no holes in space none to hide in no...   \n28632  stranded on the distant planet tschai young ad...   \n38035  in the year 2204 tragedy and terror forced a s...   \n\n                                     author  \\\n385                            Ray Bradbury   \n12563                    Robert A. Heinlein   \n18400  Jolea M. Harrison (Goodreads Author)   \n28632                            Jack Vance   \n38035                         Jack McDevitt   \n\n                                                  genres  likedPercent  \n385    ['Science Fiction', 'Fiction', 'Classics', 'Sh...          95.0  \n12563  ['Science Fiction', 'Fiction', 'Young Adult', ...          95.0  \n18400                                                 []          98.0  \n28632  ['Science Fiction', 'Fiction', 'Fantasy', 'Adv...          97.0  \n38035  ['Science Fiction', 'Fiction', 'Space Opera', ...          95.0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>title</th>\n      <th>description</th>\n      <th>author</th>\n      <th>genres</th>\n      <th>likedPercent</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>385</th>\n      <td>386</td>\n      <td>The Martian Chronicles</td>\n      <td>the strange and wonderful tale of man’s experi...</td>\n      <td>Ray Bradbury</td>\n      <td>['Science Fiction', 'Fiction', 'Classics', 'Sh...</td>\n      <td>95.0</td>\n    </tr>\n    <tr>\n      <th>12563</th>\n      <td>12661</td>\n      <td>Red Planet</td>\n      <td>jim marlow and his strangelooking martian frie...</td>\n      <td>Robert A. Heinlein</td>\n      <td>['Science Fiction', 'Fiction', 'Young Adult', ...</td>\n      <td>95.0</td>\n    </tr>\n    <tr>\n      <th>18400</th>\n      <td>18584</td>\n      <td>Union</td>\n      <td>there are no holes in space none to hide in no...</td>\n      <td>Jolea M. Harrison (Goodreads Author)</td>\n      <td>[]</td>\n      <td>98.0</td>\n    </tr>\n    <tr>\n      <th>28632</th>\n      <td>29183</td>\n      <td>Planet of Adventure</td>\n      <td>stranded on the distant planet tschai young ad...</td>\n      <td>Jack Vance</td>\n      <td>['Science Fiction', 'Fiction', 'Fantasy', 'Adv...</td>\n      <td>97.0</td>\n    </tr>\n    <tr>\n      <th>38035</th>\n      <td>38950</td>\n      <td>Deepsix</td>\n      <td>in the year 2204 tragedy and terror forced a s...</td>\n      <td>Jack McDevitt</td>\n      <td>['Science Fiction', 'Fiction', 'Space Opera', ...</td>\n      <td>95.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]}]}